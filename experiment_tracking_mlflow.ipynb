{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading data\n",
    "data = pd.read_csv('credit_card_approval_dataset.csv')\n",
    "\n",
    "# perform any necessary preprocessing, e.g. cleaning, encoding, etc.\n",
    "\n",
    "# split the data into features and target\n",
    "X = data.drop('approved', axis=1)  # assuming 'approved' is your target column\n",
    "y = data['approved']\n",
    "\n",
    "# split the data into a training set and a hold-out test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# set up MLflow\n",
    "mlflow.set_experiment(\"CreditCardApprovalExperiment\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # log some basic information\n",
    "    mlflow.log_param(\"data_shape\", data.shape)\n",
    "    mlflow.log_param(\"target_variable\", \"approved\")\n",
    "\n",
    "    # define a model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # define a grid of hyperparameters to search\n",
    "    hyperparameters = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [2, 4, 6],\n",
    "    }\n",
    "\n",
    "    # set up cross-validation grid search\n",
    "    grid_search = GridSearchCV(model, hyperparameters, cv=5, scoring='roc_auc')\n",
    "\n",
    "    # fit the model and tune hyperparameters\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # log the best parameters\n",
    "    mlflow.log_param(\"best_params\", grid_search.best_params_)\n",
    "\n",
    "    # evaluate the best model on the test set\n",
    "    y_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # log the performance metric\n",
    "    mlflow.log_metric(\"auc_roc\", auc_roc)\n",
    "\n",
    "    # log the model\n",
    "    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
